{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we'll import pytorch and check if a GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU only\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from FrEIA.modules import *\n",
    "from FrEIA.framework import *\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU available')\n",
    "else:\n",
    "    print('CPU only')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, define the path to the data we're using"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "data_path = Path('C:\\\\Users\\\\dohert01\\\\PycharmProjects\\\\qPAI_cINN_uncertainty_estimation\\\\datasets')\n",
    "experiment_name = \"FlowPhantom_insilico_complicated\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's have a look at the data. First of all, borrow some normalisation functions..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def spectrum_normalisation(spectrum):\n",
    "    \"\"\"Applies z-score scaling to the initial pressure spectrum\"\"\"\n",
    "    mean = np.mean(spectrum)\n",
    "    std = np.std(spectrum)\n",
    "    norm = (spectrum - mean)/std\n",
    "    return norm\n",
    "\n",
    "def spectrum_processing(spectrum, allowed_datapoints):\n",
    "    \"\"\"Returns a normalised initial pressure spectrum with some of the values zeroed out\"\"\"\n",
    "    num_non_zero_datapoints = random.choice(allowed_datapoints)\n",
    "    a = np.zeros(len(spectrum))\n",
    "    a[:num_non_zero_datapoints] = 1\n",
    "    np.random.shuffle(a)\n",
    "\n",
    "    incomplete_spectrum = list(np.multiply(a, np.array(spectrum)))\n",
    "    non_zero_indices = np.nonzero(incomplete_spectrum)\n",
    "    non_zero_values = list(filter(None,incomplete_spectrum))\n",
    "    normalised_non_zero = spectrum_normalisation(non_zero_values)\n",
    "\n",
    "    i = 0\n",
    "    for index in non_zero_indices[0]:\n",
    "        incomplete_spectrum[index] = normalised_non_zero[i]\n",
    "        i+=1\n",
    "\n",
    "    normalised_incomplete_spectrum = np.array(incomplete_spectrum)\n",
    "\n",
    "    return normalised_incomplete_spectrum\n",
    "\n",
    "def batch_spectrum_processing(batch, allowed_datapoints):\n",
    "    processed = []\n",
    "\n",
    "    for spectrum in batch:\n",
    "\n",
    "        processed.append(spectrum_processing(spectrum, allowed_datapoints))\n",
    "    return torch.tensor(np.array(processed))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's load the data from file"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "training_spectra_file = data_path / experiment_name / \"training_spectra.pt\"\n",
    "validation_spectra_file = data_path / experiment_name / \"validation_spectra.pt\"\n",
    "test_spectra_file = data_path / experiment_name / \"test_spectra.pt\"\n",
    "\n",
    "training_oxygenations_file = data_path / experiment_name / \"training_oxygenations.pt\"\n",
    "validation_oxygenations_file = data_path / experiment_name / \"validation_oxygenations.pt\"\n",
    "test_oxygenations_file = data_path / experiment_name / \"test_oxygenations.pt\"\n",
    "\n",
    "train_spectra_original = torch.load(training_spectra_file)\n",
    "train_oxygenations_original = torch.load(training_oxygenations_file)\n",
    "validation_spectra_original = torch.load(validation_spectra_file)\n",
    "validation_oxygenations_original = torch.load(validation_oxygenations_file)\n",
    "test_spectra_original = torch.load(test_spectra_file)\n",
    "test_oxygenations_original = torch.load(test_oxygenations_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now let's look at the dimensions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([134624, 41])\n",
      "torch.Size([134624])\n",
      "tensor([634.9278, 600.2585, 600.2339, 587.4062, 580.4452, 573.9892, 582.9027,\n",
      "        597.7095, 601.8840, 641.6681, 655.6356, 704.5982, 730.0311, 739.1377,\n",
      "        762.7631, 768.2003, 789.5642, 808.6349, 811.7870, 835.5294, 866.5328,\n",
      "        886.8488, 918.7031, 905.1712, 913.7165, 913.7761, 913.4937, 919.7126,\n",
      "        915.4688, 919.2101, 887.4873, 870.8792, 905.5049, 883.7628, 876.9416,\n",
      "        888.4904, 881.3424, 888.5063, 892.4427, 879.3855, 869.1013],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_spectra_original.size())\n",
    "print(train_oxygenations_original.size())\n",
    "print(train_spectra_original[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Zeroing out some of the spectrum data (randomly) and normalising\n",
    "allowed_datapoints = [10]\n",
    "\n",
    "train_spectra = batch_spectrum_processing(train_spectra_original, allowed_datapoints)\n",
    "validation_spectra = batch_spectrum_processing(validation_spectra_original, allowed_datapoints)\n",
    "test_spectra = batch_spectrum_processing(test_spectra_original, allowed_datapoints)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Reshaping initial pressure spectra to fit LSTM input size\n",
    "train_spectra = torch.reshape(train_spectra, (len(train_spectra), len(train_spectra[0]), 1))\n",
    "validation_spectra = torch.reshape(validation_spectra, (len(validation_spectra), len(validation_spectra[0]), 1))\n",
    "test_spectra = torch.reshape(test_spectra, (len(test_spectra), len(test_spectra[0]), 1))\n",
    "\n",
    "train_oxygenations = torch.reshape(train_oxygenations_original,(len(train_oxygenations_original),1))\n",
    "validation_oxygenations = torch.reshape(validation_oxygenations_original,(len(validation_oxygenations_original),1))\n",
    "test_oxygenations = torch.tensor(np.float32(test_oxygenations_original))\n",
    "test_oxygenations = torch.reshape(test_oxygenations_original,(len(test_oxygenations_original),1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class MultiSpectralPressureO2Dataset(Dataset):\n",
    "    def __init__(self, spectra, oxygenations, transform=None, target_transform=None):\n",
    "        self.data = spectra\n",
    "        self.labels = oxygenations\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 41])\n",
      "torch.Size([1])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.4316,  0.0000,\n",
      "          0.0000,  0.0000,  1.6534,  0.0000,  0.0000,  0.0000,  1.7502,  0.0000,\n",
      "          0.0000,  0.5177,  0.0000,  0.0000, -0.3120,  0.0000, -0.4272,  0.0000,\n",
      "         -0.6170,  0.0000,  0.0000, -0.7583,  0.0000,  0.0000, -1.0567,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -1.1817,\n",
      "          0.0000]], dtype=torch.float64)\n",
      "tensor([0.2782], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "def switch_seq_feat(tensor):\n",
    "    # Return a view of the tesor with axes rearranged\n",
    "    return torch.permute(tensor, (1, 0))\n",
    "training_dataset = MultiSpectralPressureO2Dataset(train_spectra, train_oxygenations, transform=switch_seq_feat)\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=2048, shuffle=True)\n",
    "data, label = next(iter(training_dataloader))\n",
    "data[0] = data[0].float()\n",
    "print(data[0].size())\n",
    "print(label[0].size())\n",
    "print(data[0])\n",
    "print(label[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.DoubleTensor\n",
      "torch.Size([1, 41])\n",
      "torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM for the conditioning network\n",
    "lstm = nn.LSTM(\n",
    "    41, # Input dimensions\n",
    "    100, # No. of neurons in gate networks\n",
    "    batch_first=True\n",
    ")\n",
    "# dummy inputs:\n",
    "x = torch.randn(1, 41)\n",
    "print(data[0].type())\n",
    "print(x1.size())\n",
    "print(x1.type())\n",
    "y = lstm(x1)\n",
    "print(y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time to define the model... (both LSTM and INN)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the subnet for the invertible blocks (use the AllInOneBlack from FrEIA)\n",
    "n_blocks = 10  # No. of invertible blocks in INN\n",
    "def subnet(dims_in, dims_out):\n",
    "    return nn.Sequential(nn.Linear(dims_in, 256), nn.ReLU(),\n",
    "                         nn.Linear(256, dims_out))\n",
    "\n",
    "# Define the GraphINN that combines the nodes\n",
    "nodes = [InputNode(41, 1, name='input')]\n",
    "conditions = [ConditionNode(41, 1, name='condition')]\n",
    "nodes.append(Node(nodes[-1], AllInOneBlock, {\"subnet_constructor\":subnet}, conditions=conditions[0]))\n",
    "for i in range(n_blocks):\n",
    "    nodes.append(Node([nodes[-1].out0], AllInOneBlock, {\"subnet_constructor\":subnet}, conditions=conditions[0]))\n",
    "nodes = nodes + conditions\n",
    "inn = GraphINN(nodes, verbose=True)\n",
    "\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, cond_network, inn):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cond_network = cond_network\n",
    "        self.inn = inn\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        cond = [x, self.cond_network(x).squeeze()]\n",
    "\n",
    "        z = self.inn(x, cond)\n",
    "        zz = sum(torch.sum(o**2, dim=1) for o in z)\n",
    "        jac = self.inn.jacobian(run_forward=False)\n",
    "\n",
    "        return zz, jac\n",
    "\n",
    "    def reverse_sample(self, z, cond):\n",
    "        return self.inn(z, cond, rev=True)\n",
    "\n",
    "model = WrappedModel(lstm, inn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time to define the training loop..."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Defining optimizer etc\n",
    "n_epochs = 10\n",
    "decay_by = 0.01\n",
    "weight_decay = 1e-5\n",
    "betas = (0.9, 0.999)\n",
    "log10_lr = -4.0                     # Log learning rate\n",
    "lr = 10**log10_lr\n",
    "lr_feature_net = lr                 # lr of the cond. network\n",
    "params_trainable = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "gamma = decay_by**(1./n_epochs)\n",
    "optim = torch.optim.Adam(params_trainable, lr=lr, betas=betas, eps=1e-6, weight_decay=weight_decay)\n",
    "weight_scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=1, gamma=gamma)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# a very basic training loop\n",
    "for data, label in training_dataloader:\n",
    "    optim.zero_grad()\n",
    "    # Send data to GPU (https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel)\n",
    "    data, label = data.to(device), label.to(device)\n",
    "    # pass to INN and get transformed variable z and log Jacobian determinant\n",
    "    zz, jac = model.combined_model(data)\n",
    "    # calculate the negative log-likelihood of the model with a standard normal prior\n",
    "    neg_log_likeli = 0.5 * zz - jac\n",
    "    loss = torch.mean(neg_log_likeli) / 41#tot_output_size\n",
    "    # backpropagate and update the weights\n",
    "    loss.backward()\n",
    "    optim.step()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}