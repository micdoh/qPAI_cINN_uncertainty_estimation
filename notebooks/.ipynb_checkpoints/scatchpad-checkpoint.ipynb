{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, we'll import pytorch and check if a GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from FrEIA.modules import *\n",
    "from FrEIA.framework import *\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU available')\n",
    "else:\n",
    "    print('CPU only')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Next, define the path to the data we're using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not use_cuda:\n",
    "    data_path = Path('C:\\\\Users\\\\dohert01\\\\PycharmProjects\\\\qPAI_cINN_uncertainty_estimation\\\\datasets')\n",
    "else:\n",
    "    data_path = Path('../datasets')\n",
    "\n",
    "experiment_name = \"FlowPhantom_insilico_complicated\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's have a look at the data. First of all, borrow some normalisation functions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def spectrum_normalisation(spectrum):\n",
    "    \"\"\"Applies z-score scaling to the initial pressure spectrum\"\"\"\n",
    "    mean = np.mean(spectrum)\n",
    "    std = np.std(spectrum)\n",
    "    norm = (spectrum - mean)/std\n",
    "    return norm\n",
    "\n",
    "def spectrum_processing(spectrum, allowed_datapoints):\n",
    "    \"\"\"Returns a normalised initial pressure spectrum with some of the values zeroed out\"\"\"\n",
    "    num_non_zero_datapoints = random.choice(allowed_datapoints)\n",
    "    a = np.zeros(len(spectrum))\n",
    "    a[:num_non_zero_datapoints] = 1\n",
    "    np.random.shuffle(a)\n",
    "\n",
    "    incomplete_spectrum = list(np.multiply(a, np.array(spectrum)))\n",
    "    non_zero_indices = np.nonzero(incomplete_spectrum)\n",
    "    non_zero_values = list(filter(None,incomplete_spectrum))\n",
    "    normalised_non_zero = spectrum_normalisation(non_zero_values)\n",
    "\n",
    "    i = 0\n",
    "    for index in non_zero_indices[0]:\n",
    "        incomplete_spectrum[index] = normalised_non_zero[i]\n",
    "        i+=1\n",
    "\n",
    "    normalised_incomplete_spectrum = np.array(incomplete_spectrum)\n",
    "\n",
    "    return normalised_incomplete_spectrum\n",
    "\n",
    "def batch_spectrum_processing(batch, allowed_datapoints):\n",
    "    processed = []\n",
    "\n",
    "    for spectrum in batch:\n",
    "\n",
    "        processed.append(spectrum_processing(spectrum, allowed_datapoints))\n",
    "    return torch.tensor(np.array(processed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's load the data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "training_spectra_file = data_path / experiment_name / \"training_spectra.pt\"\n",
    "validation_spectra_file = data_path / experiment_name / \"validation_spectra.pt\"\n",
    "test_spectra_file = data_path / experiment_name / \"test_spectra.pt\"\n",
    "\n",
    "training_oxygenations_file = data_path / experiment_name / \"training_oxygenations.pt\"\n",
    "validation_oxygenations_file = data_path / experiment_name / \"validation_oxygenations.pt\"\n",
    "test_oxygenations_file = data_path / experiment_name / \"test_oxygenations.pt\"\n",
    "\n",
    "train_spectra_original = torch.load(training_spectra_file)\n",
    "train_oxygenations_original = torch.load(training_oxygenations_file)\n",
    "validation_spectra_original = torch.load(validation_spectra_file)\n",
    "validation_oxygenations_original = torch.load(validation_oxygenations_file)\n",
    "test_spectra_original = torch.load(test_spectra_file)\n",
    "test_oxygenations_original = torch.load(test_oxygenations_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's look at the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([134624, 41])\n",
      "torch.Size([134624])\n",
      "tensor([634.9278, 600.2585, 600.2339, 587.4062, 580.4452, 573.9892, 582.9027,\n",
      "        597.7095, 601.8840, 641.6681, 655.6356, 704.5982, 730.0311, 739.1377,\n",
      "        762.7631, 768.2003, 789.5642, 808.6349, 811.7870, 835.5294, 866.5328,\n",
      "        886.8488, 918.7031, 905.1712, 913.7165, 913.7761, 913.4937, 919.7126,\n",
      "        915.4688, 919.2101, 887.4873, 870.8792, 905.5049, 883.7628, 876.9416,\n",
      "        888.4904, 881.3424, 888.5063, 892.4427, 879.3855, 869.1013],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(train_spectra_original.size())\n",
    "print(train_oxygenations_original.size())\n",
    "print(train_spectra_original[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Zeroing out some of the spectrum data (randomly) and normalising\n",
    "allowed_datapoints = [10]\n",
    "\n",
    "train_spectra = batch_spectrum_processing(train_spectra_original, allowed_datapoints)\n",
    "validation_spectra = batch_spectrum_processing(validation_spectra_original, allowed_datapoints)\n",
    "test_spectra = batch_spectrum_processing(test_spectra_original, allowed_datapoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Reshaping initial pressure spectra to fit LSTM input size\n",
    "train_spectra = torch.reshape(train_spectra, (len(train_spectra), len(train_spectra[0]), 1))\n",
    "validation_spectra = torch.reshape(validation_spectra, (len(validation_spectra), len(validation_spectra[0]), 1))\n",
    "test_spectra = torch.reshape(test_spectra, (len(test_spectra), len(test_spectra[0]), 1))\n",
    "\n",
    "train_oxygenations = torch.reshape(train_oxygenations_original,(len(train_oxygenations_original),1))\n",
    "validation_oxygenations = torch.reshape(validation_oxygenations_original,(len(validation_oxygenations_original),1))\n",
    "test_oxygenations = torch.tensor(np.float32(test_oxygenations_original))\n",
    "test_oxygenations = torch.reshape(test_oxygenations_original,(len(test_oxygenations_original),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MultiSpectralPressureO2Dataset(Dataset):\n",
    "    def __init__(self, spectra, oxygenations, transform=None, target_transform=None):\n",
    "        self.data = spectra\n",
    "        self.labels = oxygenations\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 41])\n",
      "torch.Size([1])\n",
      "torch.FloatTensor\n",
      "torch.FloatTensor\n",
      "tensor([[ 1.3795,  0.7354,  0.0000,  0.0000, -1.0202,  0.0000,  0.0000, -2.0495,\n",
      "          0.0000, -0.9374,  0.0377,  0.0000,  0.0000,  0.0000,  1.0638,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000,  0.0000,  0.2785,  0.0000,  0.0000,  0.4729,  0.0000,\n",
      "          0.0393]])\n",
      "tensor([0.6347])\n"
     ]
    }
   ],
   "source": [
    "def switch_seq_feat(tensor):\n",
    "    # Return a view of the tesor with axes rearranged\n",
    "    return torch.permute(tensor, (1, 0)).float()\n",
    "def float_transform(tensor):\n",
    "    return tensor.float()\n",
    "training_dataset = MultiSpectralPressureO2Dataset(\n",
    "    train_spectra, \n",
    "    train_oxygenations, \n",
    "    transform=switch_seq_feat, \n",
    "    target_transform=float_transform\n",
    ")\n",
    "training_dataloader = DataLoader(training_dataset, batch_size=2048, shuffle=True)\n",
    "data, label = next(iter(training_dataloader))\n",
    "\n",
    "print(data[0].size())\n",
    "print(label[0].size())\n",
    "print(data[0].type())\n",
    "print(label[0].type())\n",
    "print(data[0])\n",
    "print(label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.FloatTensor\n",
      "torch.Size([1, 41])\n",
      "torch.FloatTensor\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "# Define the LSTM for the conditioning network\n",
    "lstm = nn.LSTM(\n",
    "    41, # Input dimensions\n",
    "    100, # No. of neurons in gate networks\n",
    "    batch_first=True\n",
    ")\n",
    "# dummy inputs:\n",
    "x = torch.randn(1, 41)\n",
    "print(data[0].type())\n",
    "print(x.size())\n",
    "print(x.type())\n",
    "y = lstm(data[0])[0]\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Time to define the model... (both LSTM and INN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define the subnet for the invertible blocks (use the AllInOneBlack from FrEIA)\n",
    "n_blocks = 10  # No. of invertible blocks in INN\n",
    "def subnet(dims_in, dims_out):\n",
    "    return nn.Sequential(nn.Linear(dims_in, 256), nn.ReLU(),\n",
    "                         nn.Linear(256, dims_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define the INN as sequential or as a Graph. The cell below is a GraphINN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnodes = [InputNode(41, 1, name=\\'input\\')]\\nconditions = [ConditionNode(100, 1, name=\\'condition\\')]\\nnodes.append(Node(nodes[-1], AllInOneBlock, {\"subnet_constructor\":subnet}, conditions=conditions[0]))\\nfor i in range(n_blocks):\\n    nodes.append(Node([nodes[-1].out0], AllInOneBlock, {\"subnet_constructor\":subnet}, conditions=conditions[0]))\\nnodes = nodes + conditions\\nprint(nodes)\\ninn = GraphINN(nodes, verbose=True)\\n\\nclass WrappedModel(nn.Module):\\n    def __init__(self, cond_network, inn):\\n        super().__init__()\\n\\n        self.cond_network = cond_network\\n        self.inn = inn\\n\\n    def forward(self, x):\\n\\n        cond = [x, self.cond_network(x).squeeze()]\\n\\n        z = self.inn(x, cond)\\n        zz = sum(torch.sum(o**2, dim=1) for o in z)\\n        jac = self.inn.jacobian(run_forward=False)\\n\\n        return zz, jac\\n\\n    def reverse_sample(self, z, cond):\\n        return self.inn(z, cond, rev=True)\\n\\nmodel = WrappedModel(lstm, inn)\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the GraphINN that combines the nodes\n",
    "\"\"\"\n",
    "nodes = [InputNode(41, 1, name='input')]\n",
    "conditions = [ConditionNode(100, 1, name='condition')]\n",
    "nodes.append(Node(nodes[-1], AllInOneBlock, {\"subnet_constructor\":subnet}, conditions=conditions[0]))\n",
    "for i in range(n_blocks):\n",
    "    nodes.append(Node([nodes[-1].out0], AllInOneBlock, {\"subnet_constructor\":subnet}, conditions=conditions[0]))\n",
    "nodes = nodes + conditions\n",
    "print(nodes)\n",
    "inn = GraphINN(nodes, verbose=True)\n",
    "\n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, cond_network, inn):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cond_network = cond_network\n",
    "        self.inn = inn\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        cond = [x, self.cond_network(x).squeeze()]\n",
    "\n",
    "        z = self.inn(x, cond)\n",
    "        zz = sum(torch.sum(o**2, dim=1) for o in z)\n",
    "        jac = self.inn.jacobian(run_forward=False)\n",
    "\n",
    "        return zz, jac\n",
    "\n",
    "    def reverse_sample(self, z, cond):\n",
    "        return self.inn(z, cond, rev=True)\n",
    "\n",
    "model = WrappedModel(lstm, inn)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "The next cell is defined as a SequentialINN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "inn = SequenceINN(41, 1)\n",
    "\n",
    "for i in range(n_blocks):\n",
    "    # TODO - Consider clamping and permute_soft arguments\n",
    "    inn.append(AllInOneBlock, cond=0, cond_shape=(100, 1), subnet_constructor=subnet)\n",
    "    \n",
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self, cond_network, inn):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cond_network = cond_network\n",
    "        self.inn = inn\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        #cond = [x, self.cond_network(x).squeeze()]\n",
    "        cond = self.cond_network(x)\n",
    "\n",
    "        z = self.inn(x, cond)\n",
    "        zz = sum(torch.sum(o**2, dim=1) for o in z)\n",
    "        jac = self.inn.jacobian(run_forward=False)\n",
    "\n",
    "        return zz, jac\n",
    "\n",
    "    def reverse_sample(self, z, cond):\n",
    "        return self.inn(z, cond, rev=True)\n",
    "\n",
    "model = WrappedModel(lstm, inn)\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Time to define the training loop..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Defining optimizer etc\n",
    "n_epochs = 10\n",
    "decay_by = 0.01\n",
    "weight_decay = 1e-5\n",
    "betas = (0.9, 0.999)\n",
    "log10_lr = -4.0                     # Log learning rate\n",
    "lr = 10**log10_lr\n",
    "lr_feature_net = lr                 # lr of the cond. network\n",
    "params_trainable = list(filter(lambda p: p.requires_grad, model.parameters()))\n",
    "gamma = decay_by**(1./n_epochs)\n",
    "optim = torch.optim.Adam(params_trainable, lr=lr, betas=betas, eps=1e-6, weight_decay=weight_decay)\n",
    "weight_scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=1, gamma=gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                   \r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_2157431/2836169093.py\", line 19, in forward\n    z = self.inn(x, cond)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/FrEIA/framework/sequence_inn.py\", line 106, in forward\n    x_or_z, j = self.module_list[i](x_or_z, c=[c[self.conditions[i]]],\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/FrEIA/modules/all_in_one_block.py\", line 240, in forward\n    x1, x2 = torch.split(x[0], self.splits, dim=1)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/functional.py\", line 159, in split\n    return tensor.split(split_size_or_sections, dim)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/_tensor.py\", line 574, in split\n    return super(Tensor, self).split_with_sizes(split_size, dim)\nRuntimeError: start (0) + length (21) exceeds dimension size (1).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Send data to GPU (https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#data, label = data.to(device), label.to(device)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# pass to INN and get transformed variable z and log Jacobian determinant\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m zz, jac \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# calculate the negative log-likelihood of the model with a standard normal prior\u001b[39;00m\n\u001b[1;32m     18\u001b[0m neg_log_likeli \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m zz \u001b[38;5;241m-\u001b[39m jac\n",
      "File \u001b[0;32m/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:168\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    167\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 168\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:178\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas, inputs, kwargs):\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py:86\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     84\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m---> 86\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/_utils.py:457\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 457\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in replica 0 on device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\", line 61, in _worker\n    output = module(*input, **kwargs)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/tmp/ipykernel_2157431/2836169093.py\", line 19, in forward\n    z = self.inn(x, cond)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/FrEIA/framework/sequence_inn.py\", line 106, in forward\n    x_or_z, j = self.module_list[i](x_or_z, c=[c[self.conditions[i]]],\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/nn/modules/module.py\", line 1110, in _call_impl\n    return forward_call(*input, **kwargs)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/FrEIA/modules/all_in_one_block.py\", line 240, in forward\n    x1, x2 = torch.split(x[0], self.splits, dim=1)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/functional.py\", line 159, in split\n    return tensor.split(split_size_or_sections, dim)\n  File \"/home/cri.camres.org/dohert01/.cache/pypoetry/virtualenvs/qpai-cinn-uncertainty-estimation-wWg_2NH5-py3.8/lib/python3.8/site-packages/torch/_tensor.py\", line 574, in split\n    return super(Tensor, self).split_with_sizes(split_size, dim)\nRuntimeError: start (0) + length (21) exceeds dimension size (1).\n"
     ]
    }
   ],
   "source": [
    "# a very basic training loop\n",
    "#for data, label in training_dataloader:\n",
    "iterator = tqdm.tqdm(enumerate(iter(training_dataloader)),\n",
    "                     total=len(training_dataloader),\n",
    "                     leave=False,\n",
    "                     mininterval=1.,\n",
    "                     ncols=83)\n",
    "for i_batch, x in iterator:\n",
    "    #print(len(x))\n",
    "    #print(x[0].size())\n",
    "    #break\n",
    "    optim.zero_grad()\n",
    "    # Send data to GPU (https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel)\n",
    "    #data, label = data.to(device), label.to(device)\n",
    "    # pass to INN and get transformed variable z and log Jacobian determinant\n",
    "    zz, jac = model.forward(x[0])\n",
    "    # calculate the negative log-likelihood of the model with a standard normal prior\n",
    "    neg_log_likeli = 0.5 * zz - jac\n",
    "    loss = torch.mean(neg_log_likeli) / 41#tot_output_size\n",
    "    # backpropagate and update the weights\n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
